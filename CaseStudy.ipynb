{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the environment\n",
    "Loading models and tokenizers for CLAP and calculating SHA-256 hash of CLAP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfs/u2020-fy/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.multiprocessing\n",
    "import torch\n",
    "import torch.nn.functional as F  \n",
    "import json\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "asm_tokenizer       = AutoTokenizer.from_pretrained(\"hustcw/clap-asm\", trust_remote_code=True)\n",
    "text_tokenizer      = AutoTokenizer.from_pretrained(\"hustcw/clap-text\", trust_remote_code=True)\n",
    "asm_encoder         = AutoModel.from_pretrained(\"hustcw/clap-asm\", trust_remote_code=True).to(device)\n",
    "text_encoder        = AutoModel.from_pretrained(\"hustcw/clap-text\", trust_remote_code=True).to(device)\n",
    "\n",
    "bubble_output       = \"./CaseStudy/bubblesort.json\"\n",
    "malware_output      = \"./CaseStudy/malware.json\"\n",
    "sha3              = \"./CaseStudy/sha3.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 抗干扰的代码建模验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between before and after embeddings: 0.9395756721496582\n"
     ]
    }
   ],
   "source": [
    "before_bi = \"./LinuxBinary/ops.iwl_mvm_stop_device.before.o.json\"\n",
    "after_bi = \"./LinuxBinary/ops.iwl_mvm_stop_device.after.o.json\"\n",
    "\n",
    "with open(before_bi) as fp:\n",
    "    asm = json.load(fp)\n",
    "with torch.no_grad():\n",
    "    before_input = asm_tokenizer([asm[0]], padding=True, pad_to_multiple_of=8, return_tensors=\"pt\", verbose=False)\n",
    "    before_input = before_input.to(device)\n",
    "    before_embedding = asm_encoder(**before_input)\n",
    "\n",
    "with open(after_bi) as fp:\n",
    "    asm = json.load(fp)\n",
    "with torch.no_grad():\n",
    "    after_input = asm_tokenizer([asm[0]], padding=True, pad_to_multiple_of=8, return_tensors=\"pt\", verbose=False)\n",
    "    after_input = after_input.to(device)\n",
    "    after_embedding = asm_encoder(**after_input)\n",
    "  \n",
    "# L2 归一化嵌入  \n",
    "before_embedding_norm = F.normalize(before_embedding, dim=-1)  \n",
    "after_embedding_norm = F.normalize(after_embedding, dim=-1)  \n",
    "  \n",
    "# 计算余弦相似度  \n",
    "cosine_similarity = F.cosine_similarity(before_embedding_norm, after_embedding_norm, dim=-1).item()  \n",
    "  \n",
    "print(f\"Cosine similarity between before and after embeddings: {cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interference         State      Cosine Sim Before  Cosine Sim After   Pred State Success\n",
      "----------------------------------------------------------------------------------------------------\n",
      "32                   after      0.756176           0.823715           after      yes  \n",
      "arch64               after      0.764591           0.807831           after      yes  \n",
      "clang                after      0.933223           0.991611           after      yes  \n",
      "Os                   after      0.939576           1.000000           after      yes  \n",
      "32                   before     0.761585           0.700692           before     yes  \n",
      "arch64               before     0.697337           0.678633           before     yes  \n",
      "clang                before     0.989663           0.935799           before     yes  \n",
      "Os                   before     1.000000           0.939576           before     yes  \n"
     ]
    }
   ],
   "source": [
    "# 读取LinuxBinary.json文件  \n",
    "with open(\"LinuxBinary.json\") as fp:  \n",
    "    data = json.load(fp)  \n",
    "\n",
    "results = []\n",
    "\n",
    "for data_item in data:\n",
    "    result = {}\n",
    "    # 获取第一个数组元素的“files”值  \n",
    "    files = data_item[\"files\"]  \n",
    "    result['cve'] = data_item[\"folder_name\"]\n",
    "    result['results'] = []\n",
    "    \n",
    "    # 存储所有嵌入和相关信息  \n",
    "    embeddings = {}  \n",
    "    info = []  \n",
    "    \n",
    "    # 遍历“files”数组  \n",
    "    for file_info in files:  \n",
    "        state = file_info[\"state\"]  \n",
    "        interference = file_info.get(\"interference\")  \n",
    "        asm_value = file_info[\"asm\"]  \n",
    "    \n",
    "        # 获取asm的嵌入表示  \n",
    "        with torch.no_grad():  \n",
    "            asm_input = asm_tokenizer([asm_value], padding=True, pad_to_multiple_of=8, return_tensors=\"pt\", verbose=False)  \n",
    "            asm_input = asm_input.to(device)  \n",
    "            embedding = asm_encoder(**asm_input)  \n",
    "            embedding_norm = F.normalize(embedding, dim=-1)  # L2归一化  \n",
    "    \n",
    "        # 存储嵌入和相关信息  \n",
    "        embeddings[(state, interference)] = embedding_norm.cpu().numpy()  # 存储为numpy数组以便后续比较  \n",
    "        info.append({  \n",
    "            \"state\": state,  \n",
    "            \"interference\": interference,  \n",
    "            \"asm\": asm_value  # 这里只是保留原始asm值，实际上可能不需要在最终结果中打印  \n",
    "        })  \n",
    "    \n",
    "    # 分离“interference”为None的项，并分别获取“state”为before和after的嵌入  \n",
    "    none_interference_embeddings = {  \n",
    "        \"before\": None,  \n",
    "        \"after\": None  \n",
    "    }  \n",
    "    for info_item in info:  \n",
    "        if info_item[\"interference\"] == \"none\":  \n",
    "            state = info_item[\"state\"]  \n",
    "            none_interference_embeddings[state] = embeddings[(state, \"none\")]  \n",
    "    \n",
    "    # 计算余弦相似度并确定“pred_state”和“success”  \n",
    "    for info_item in info:  \n",
    "        if info_item[\"interference\"] != 'none':  \n",
    "            state = info_item[\"state\"]  \n",
    "            embedding_norm_np = embeddings[(state, info_item[\"interference\"])].squeeze()  \n",
    "    \n",
    "            # 计算与“interference”为None项的余弦相似度  \n",
    "            cosine_sim_before = F.cosine_similarity(  \n",
    "                torch.tensor(embedding_norm_np, dtype=torch.float32).to(device),  \n",
    "                torch.tensor(none_interference_embeddings[\"before\"], dtype=torch.float32).to(device)  \n",
    "            ).item()  \n",
    "            cosine_sim_after = F.cosine_similarity(  \n",
    "                torch.tensor(embedding_norm_np, dtype=torch.float32).to(device),  \n",
    "                torch.tensor(none_interference_embeddings[\"after\"], dtype=torch.float32).to(device)  \n",
    "            ).item()  \n",
    "    \n",
    "            # 确定“pred_state”  \n",
    "            pred_state = \"after\" if cosine_sim_after > cosine_sim_before else \"before\"  \n",
    "    \n",
    "            # 确定“success”  \n",
    "            success = \"yes\" if pred_state == state else \"no\"  \n",
    "    \n",
    "            # 添加到结果列表  \n",
    "            info_item.update({  \n",
    "                \n",
    "            })  \n",
    "            result['results'].append(\n",
    "                {   \n",
    "                    \"interference\": info_item[\"interference\"],  \n",
    "                    \"state\": info_item[\"state\"],\n",
    "                    \"cosine_sim_before\": cosine_sim_before,  \n",
    "                    \"cosine_sim_after\": cosine_sim_after,  \n",
    "                    \"pred_state\": pred_state,  \n",
    "                    \"success\": success  \n",
    "                }\n",
    "            )\n",
    "    results.append(result)\n",
    "    # 打印结果表格  \n",
    "    print(f\"{'Interference':<20} {'State':<10} {'Cosine Sim Before':<18} {'Cosine Sim After':<18} {'Pred State':<10} {'Success':<5}\")  \n",
    "    print(\"-\" * 100)  \n",
    "    for item in result['results']:  \n",
    "        if item[\"interference\"] != \"none\":  \n",
    "            print(f\"{item['interference']:<20} {item['state']:<10} {item['cosine_sim_before']:<18.6f} {item['cosine_sim_after']:<18.6f} {item['pred_state']:<10} {item['success']:<5}\")\n",
    "\n",
    "            \n",
    "with open(\"Results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-grained sorting algorithm classification (Zero-Shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([1, 72])\n",
      "attention_mask: torch.Size([1, 72])\n",
      "token_type_ids: torch.Size([1, 72])\n",
      "asm_embedding shape: torch.Size([1, 768])\n",
      "bubblesort zeroshot:\n",
      "Probability: 18.425%, Text: This is a function related to bubble sort \n",
      "Probability: 6.845%, Text: This is a function related to selection sort\n",
      "Probability: 11.032%, Text: This is a function related to insertion sort\n",
      "Probability: 5.169%, Text: This is a function related to merge sort\n",
      "Probability: 9.403%, Text: This is a function related to quick sort\n",
      "Probability: 13.112%, Text: This is a function related to radix sort\n",
      "Probability: 12.292%, Text: This is a function related to shell sort\n",
      "Probability: 10.073%, Text: This is a function related to counting sort\n",
      "Probability: 9.4%, Text: This is a function related to bucket sort\n",
      "Probability: 4.249%, Text: This is a function related to heap sort\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(bubble_output) as fp:\n",
    "    asm = json.load(fp)\n",
    "\n",
    "prompts = [\n",
    "    \"This is a function related to bubble sort \",\n",
    "    \"This is a function related to selection sort\",\n",
    "    \"This is a function related to insertion sort\",\n",
    "    \"This is a function related to merge sort\",\n",
    "    \"This is a function related to quick sort\",\n",
    "    \"This is a function related to radix sort\",\n",
    "    \"This is a function related to shell sort\",\n",
    "    \"This is a function related to counting sort\",\n",
    "    \"This is a function related to bucket sort\",\n",
    "    \"This is a function related to heap sort\",\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    asm_input = asm_tokenizer([asm], padding=True, pad_to_multiple_of=8, return_tensors=\"pt\", verbose=False)\n",
    "    asm_input = asm_input.to(device)\n",
    "    asm_embedding = asm_encoder(**asm_input)\n",
    "\n",
    "with torch.no_grad():\n",
    "    text_input = text_tokenizer(prompts, padding=True, truncation=True, return_tensors='pt')\n",
    "    text_input = text_input.to(device)\n",
    "    text_embeddings = text_encoder(**text_input)\n",
    "\n",
    "logits = torch.einsum(\"nc,ck->nk\", [asm_embedding, text_embeddings.T])\n",
    "_, preds = torch.max(logits, dim=1)\n",
    "preds = torch.softmax(logits / 0.07, dim=1).squeeze(0).tolist()\n",
    "\n",
    "print(\"bubblesort zeroshot:\")\n",
    "for i in range(len(prompts)):\n",
    "    print(f\"Probability: {round(preds[i]*100, 3)}%, Text: {prompts[i]}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-grained malware functionality classification (Zero-Shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([1, 1024])\n",
      "attention_mask: torch.Size([1, 1024])\n",
      "token_type_ids: torch.Size([1, 1024])\n",
      "asm_embedding shape: torch.Size([1, 768])\n",
      "malware zeroshot:\n",
      "Probability: 78.529%, Text: This is a function related to screen shot\n",
      "Probability: 6.667%, Text: This is a function related to auto start\n",
      "Probability: 1.386%, Text: This is a function related to backdoor\n",
      "Probability: 1.536%, Text: This is a function related to download\n",
      "Probability: 2.315%, Text: This is a function related to upload\n",
      "Probability: 2.946%, Text: This is a function related to rootkit\n",
      "Probability: 1.304%, Text: This is a function related to anti detect\n",
      "Probability: 2.994%, Text: This is a function related to anti debug\n",
      "Probability: 0.829%, Text: This is a function related to passwords brute force\n",
      "Probability: 1.495%, Text: This is a function related to file hijack\n"
     ]
    }
   ],
   "source": [
    "with open(malware_output) as fp:\n",
    "    asm = json.load(fp)\n",
    "\n",
    "prompts = [\n",
    "    \"This is a function related to screen shot\",\n",
    "    \"This is a function related to auto start\",\n",
    "    \"This is a function related to backdoor\",\n",
    "    \"This is a function related to download\",\n",
    "    \"This is a function related to upload\",\n",
    "    \"This is a function related to rootkit\",\n",
    "    \"This is a function related to anti detect\",\n",
    "    \"This is a function related to anti debug\",\n",
    "    \"This is a function related to passwords brute force\",\n",
    "    \"This is a function related to file hijack\",\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    asm_input = asm_tokenizer([asm], padding=True, pad_to_multiple_of=8, return_tensors=\"pt\", verbose=False)\n",
    "    asm_input = asm_input.to(device)\n",
    "    # 打印每个张量的形状\n",
    "    for key, value in asm_input.items():\n",
    "        print(f\"{key}: {value.shape}\")\n",
    "    asm_embedding = asm_encoder(**asm_input)\n",
    "    print(f\"asm_embedding shape: {asm_embedding.shape}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    text_input = text_tokenizer(prompts, padding=True, truncation=True, return_tensors='pt')\n",
    "    text_input = text_input.to(device)\n",
    "    text_embeddings = text_encoder(**text_input)\n",
    "\n",
    "logits = torch.einsum(\"nc,ck->nk\", [asm_embedding, text_embeddings.T])\n",
    "_, preds = torch.max(logits, dim=1)\n",
    "preds = torch.softmax(logits / 0.07, dim=1).squeeze(0).tolist()\n",
    "\n",
    "print(\"malware zeroshot:\")\n",
    "for i in range(len(prompts)):\n",
    "    print(f\"Probability: {round(preds[i]*100, 3)}%, Text: {prompts[i]}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-grained crypto algorithm classification (Zero-Shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sha3 zeroshot:\n",
      "Probability: 62.579%, Text: This is a function related to sha3\n",
      "Probability: 1.63%, Text: This is a function related to des\n",
      "Probability: 3.479%, Text: This is a function related to bubble sort\n",
      "Probability: 24.634%, Text: This is a function related to md5\n",
      "Probability: 5.705%, Text: This is a function related to rsa\n",
      "Probability: 1.974%, Text: This is a function related to sm4\n"
     ]
    }
   ],
   "source": [
    "with open(sha3) as fp:\n",
    "    asm = json.load(fp)\n",
    "\n",
    "prompts = [\n",
    "    \"This is a function related to sha3\",\n",
    "    \"This is a function related to des\",\n",
    "    \"This is a function related to bubble sort\",\n",
    "    \"This is a function related to md5\",\n",
    "    \"This is a function related to rsa\",\n",
    "    \"This is a function related to sm4\"\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    asm_input = asm_tokenizer([asm], padding=True, pad_to_multiple_of=8, return_tensors=\"pt\", verbose=False)\n",
    "    asm_input = asm_input.to(device)\n",
    "    asm_embedding = asm_encoder(**asm_input)\n",
    "\n",
    "with torch.no_grad():\n",
    "    text_input = text_tokenizer(prompts, padding=True, truncation=True, return_tensors='pt')\n",
    "    text_input = text_input.to(device)\n",
    "    text_embeddings = text_encoder(**text_input)\n",
    "\n",
    "logits = torch.einsum(\"nc,ck->nk\", [asm_embedding, text_embeddings.T])\n",
    "_, preds = torch.max(logits, dim=1)\n",
    "preds = torch.softmax(logits / 0.07, dim=1).squeeze(0).tolist()\n",
    "\n",
    "print(\"sha3 zeroshot:\")\n",
    "for i in range(len(prompts)):\n",
    "    print(f\"Probability: {round(preds[i]*100, 3)}%, Text: {prompts[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
